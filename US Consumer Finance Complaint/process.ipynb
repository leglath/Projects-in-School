{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started loading complaintsinitial.csv at 2024-04-23 11:07:48.884041\n",
      "finished loading complaintsinitial.csv at 2024-04-23 11:08:05.321565\n",
      "(1741869, 18)\n",
      "Number of unique values per column:-\n",
      " Date received                      1096\n",
      "Product                               9\n",
      "Sub-product                          48\n",
      "Issue                                81\n",
      "Sub-issue                           167\n",
      "Consumer complaint narrative     583626\n",
      "Company public response              10\n",
      "Company                            4735\n",
      "State                                61\n",
      "ZIP code                          23645\n",
      "Tags                                  3\n",
      "Consumer consent provided?            4\n",
      "Submitted via                         7\n",
      "Date sent to company               1171\n",
      "Company response to consumer          5\n",
      "Timely response?                      2\n",
      "Consumer disputed?                    0\n",
      "Complaint ID                    1741869\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "Number of missing values per column:-\n",
      " Date received                         0\n",
      "Product                               0\n",
      "Sub-product                          93\n",
      "Issue                                 0\n",
      "Sub-issue                        130915\n",
      "Consumer complaint narrative    1026266\n",
      "Company public response          830200\n",
      "Company                               0\n",
      "State                             15840\n",
      "ZIP code                           9844\n",
      "Tags                            1583239\n",
      "Consumer consent provided?       132700\n",
      "Submitted via                         0\n",
      "Date sent to company                  0\n",
      "Company response to consumer          1\n",
      "Timely response?                      0\n",
      "Consumer disputed?              1741869\n",
      "Complaint ID                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"started loading complaintsinitial.csv at\",datetime.now())\n",
    "df_initial = pd.read_csv('complaintsinitial.csv') #1.27 GB \n",
    "print(\"finished loading complaintsinitial.csv at\",datetime.now())  #15 seconds to load\n",
    "\n",
    "print(df_initial.shape) # 1741869 rows, 18 columns\n",
    "\n",
    "#get number of unique values per column\n",
    "unique_values_per_column = df_initial.nunique();\n",
    "\n",
    "print(\"Number of unique values per column:-\\n\" , unique_values_per_column);\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#get number of missing values per column\n",
    "nan_counts_per_column = df_initial.isna().sum()\n",
    "print(\"Number of missing values per column:-\\n\" , nan_counts_per_column );\n",
    "\n",
    "#The following rows are missing 0 values (all categorical variables) - Product (9 unique), Issue(81 unique), Company(4735 unique), Submitted via(7 unique), Timely response(2 unique)\n",
    "\n",
    "#sub-product missing 93 values out of 1741869 so will remove these rows as we might want to include it as a predictor variable since it only has 48 unique values \n",
    "df_initial = df_initial[~df_initial['Sub-product'].isna()]\n",
    "\n",
    "#drop the following columns\n",
    "#Consumer complaint narrative - free text\n",
    "#Tags - 1583239 missing out of 1741869 total\n",
    "#Date sent to company. Over 92% are the same day as date received and of the remaining 8% almost all are within 1 week so high collinearity\n",
    "# Zip codes as these have high cardinality, which could lead to overfitting. We have enough other variables to ensure we don't underfit. Also a number missing or have XX\n",
    "# Complaint ID is unique per complaint so also has high cardinality\n",
    "#Customer disputed? has no data\n",
    "\n",
    "df_Group6 = df_initial.drop(['Consumer complaint narrative','Tags','Date sent to company','ZIP code','Complaint ID','Consumer disputed?'],axis=1)\n",
    "\n",
    "del df_initial # remove from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompanyResponse(df):\n",
    "    # Create a new column 'Closed with monetary relief' and set it to 1 where 'Company response to consumer' equals 'Closed with monetary relief', \n",
    "    # else set it to 0\n",
    "    df['Closed with monetary relief'] = (df['Company response to consumer'] == 'Closed with monetary relief').astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetValueCounts(df, predictor_var):\n",
    "    print(\"\\n\")\n",
    "    print(f\"Count of variables for predictor variable '{predictor_var}':\")\n",
    "    print(df[predictor_var].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Count of variables for predictor variable 'Closed with monetary relief':\n",
      "Closed with monetary relief\n",
      "0    1697810\n",
      "1      43966\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Count of variables for predictor variable 'Product':\n",
      "Product\n",
      "Credit reporting, credit repair services, or other personal consumer reports    1196468\n",
      "Debt collection                                                                  183830\n",
      "Credit card or prepaid card                                                      105629\n",
      "Checking or savings account                                                       91356\n",
      "Mortgage                                                                          74489\n",
      "Money transfer, virtual currency, or money service                                35757\n",
      "Vehicle loan or lease                                                             23463\n",
      "Student loan                                                                      16477\n",
      "Payday loan, title loan, or personal loan                                         14307\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Count of variables for predictor variable 'Issue':\n",
      "Issue\n",
      "Incorrect information on your report                                                591446\n",
      "Problem with a credit reporting company's investigation into an existing problem    332230\n",
      "Improper use of your report                                                         257076\n",
      "Attempts to collect debt not owed                                                    98219\n",
      "Managing an account                                                                  56569\n",
      "Written notification about debt                                                      40917\n",
      "Trouble during payment process                                                       34952\n",
      "Problem with a purchase shown on your statement                                      27218\n",
      "Struggling to pay mortgage                                                           16393\n",
      "Unable to get your credit report or credit score                                     15449\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#set 'Closed with monetary relief' variable to 1 where 'Company response to consumer' equals 'Closed with monetary relief' else 0. This is the predictor variable for our models\n",
    "CompanyResponse(df_Group6)  \n",
    "\n",
    "# The following code shows the distribution of classes in our predictors and response variable. Specifically we see that only 43966 (just over 2.5%) are marked with 'Closed with monetary relief while 1697810 out of 1741776 (almost 97.5%) are marked as other\n",
    "\n",
    "for predictor_var in ('Closed with monetary relief','Product', 'Issue'):\n",
    "    GetValueCounts(df_Group6,predictor_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.131544\n",
      "         Iterations 8\n",
      "The confusion matrix (training set) for this model is\n",
      " [[1358281       0]\n",
      " [  35139       0]]\n",
      "The confusion matrix (testing set) for this model is\n",
      " [[339529      0]\n",
      " [  8827      0]]\n",
      "\n",
      "Model 1 summary statistics:\n",
      "\n",
      "                               Results: Logit\n",
      "=============================================================================\n",
      "Model:              Logit                       Method:           MLE        \n",
      "Dependent Variable: Closed with monetary relief Pseudo R-squared: -0.118     \n",
      "Date:               2024-04-23 11:38            AIC:              366594.8939\n",
      "No. Observations:   1393420                     BIC:              366607.0411\n",
      "Df Model:           0                           Log-Likelihood:   -1.8330e+05\n",
      "Df Residuals:       1393419                     LL-Null:          -1.6401e+05\n",
      "Converged:          1.0000                      LLR p-value:      nan        \n",
      "No. Iterations:     8.0000                      Scale:            1.0000     \n",
      "--------------------------------------------------------------------------------\n",
      "                 Coef.     Std.Err.        z        P>|z|      [0.025     0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "ProductCodes    -1.9237      0.0033    -583.8124    0.0000    -1.9301    -1.9172\n",
      "=============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y=df_Group6['Closed with monetary relief']  #response variable\n",
    "\n",
    "# Need numeric values for logistic regression. Do in this order to avoid warnings\n",
    "X = df_Group6[['Product', 'Issue']].copy()\n",
    "X['ProductCodes'] = X['Product'].astype('category').cat.codes\n",
    "X['IssueCodes'] = X['Issue'].astype('category').cat.codes\n",
    "\n",
    "# Split data into training and testing sets (splitting 80:20 train:test) \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=21)\n",
    "\n",
    "# First we fit a logistic regression model with product codes & response variable 'Closed with monetary relief' (1 or 0)\n",
    "\n",
    "model1 = sm.Logit(y_train, x_train['ProductCodes']).fit()\n",
    "print(\"The confusion matrix (training set) for this model is\\n\", confusion_matrix(y_train, model1.predict(x_train['ProductCodes'])>0.5))\n",
    "print(\"The confusion matrix (testing set) for this model is\\n\", confusion_matrix(y_test, model1.predict(x_test['ProductCodes'])>0.5))\n",
    "\n",
    "print(\"\\nModel 1 summary statistics:\\n\")\n",
    "print(model1.summary2())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.119301\n",
      "         Iterations 8\n",
      "The confusion matrix (training set) for this model is\n",
      " [[1358281       0]\n",
      " [  35139       0]]\n",
      "The confusion matrix (testing set) for this model is\n",
      " [[339529      0]\n",
      " [  8827      0]]\n",
      "\n",
      "Model 2 summary statistics:\n",
      "\n",
      "                               Results: Logit\n",
      "=============================================================================\n",
      "Model:              Logit                       Method:           MLE        \n",
      "Dependent Variable: Closed with monetary relief Pseudo R-squared: -0.014     \n",
      "Date:               2024-04-23 11:39            AIC:              332477.5024\n",
      "No. Observations:   1393420                     BIC:              332501.7969\n",
      "Df Model:           1                           Log-Likelihood:   -1.6624e+05\n",
      "Df Residuals:       1393418                     LL-Null:          -1.6401e+05\n",
      "Converged:          1.0000                      LLR p-value:      1.0000     \n",
      "No. Iterations:     8.0000                      Scale:            1.0000     \n",
      "--------------------------------------------------------------------------------\n",
      "                 Coef.     Std.Err.        z        P>|z|      [0.025     0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "ProductCodes    -1.3033      0.0045    -292.5879    0.0000    -1.3120    -1.2946\n",
      "IssueCodes      -0.0385      0.0002    -167.9420    0.0000    -0.0389    -0.0380\n",
      "=============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now we fit a logistic regression model with product codes and issue codes as predictor variables\n",
    "\n",
    "model2 = sm.Logit(y_train, x_train[['ProductCodes','IssueCodes']]).fit()\n",
    "print(\"The confusion matrix (training set) for this model is\\n\", confusion_matrix(y_train, model2.predict(x_train[['ProductCodes','IssueCodes']])>0.5))\n",
    "print(\"The confusion matrix (testing set) for this model is\\n\", confusion_matrix(y_test, model2.predict(x_test[['ProductCodes','IssueCodes']])>0.5))\n",
    "\n",
    "\n",
    "print(\"\\nModel 2 summary statistics:\\n\")\n",
    "print(model2.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    threshold  Training TPR  Training TNR  Test TPR  Test TNR\n",
      "0        0.49      0.000000      1.000000  0.000000  1.000000\n",
      "1        0.48      0.000000      1.000000  0.000000  1.000000\n",
      "2        0.47      0.000000      1.000000  0.000000  1.000000\n",
      "3        0.46      0.000000      1.000000  0.000000  1.000000\n",
      "4        0.45      0.000000      1.000000  0.000000  1.000000\n",
      "5        0.44      0.000000      1.000000  0.000000  1.000000\n",
      "6        0.43      0.037366      0.993700  0.032174  0.993512\n",
      "7        0.42      0.037366      0.993700  0.032174  0.993512\n",
      "8        0.41      0.037366      0.993700  0.032174  0.993512\n",
      "9        0.40      0.037366      0.993700  0.032174  0.993512\n",
      "10       0.39      0.037366      0.993700  0.032174  0.993512\n",
      "11       0.38      0.037366      0.993700  0.032174  0.993512\n",
      "12       0.37      0.037366      0.993700  0.032174  0.993512\n",
      "13       0.36      0.037480      0.993684  0.032174  0.993497\n",
      "14       0.35      0.037480      0.993684  0.032174  0.993497\n",
      "15       0.34      0.037480      0.993684  0.032174  0.993497\n",
      "16       0.33      0.037480      0.993684  0.032174  0.993497\n",
      "17       0.32      0.037480      0.993684  0.032174  0.993497\n",
      "18       0.31      0.037480      0.993684  0.032174  0.993497\n",
      "19       0.30      0.037480      0.993684  0.032174  0.993497\n",
      "20       0.29      0.037480      0.993684  0.032174  0.993497\n",
      "21       0.28      0.037480      0.993684  0.032174  0.993497\n",
      "22       0.27      0.037480      0.993684  0.032174  0.993497\n",
      "23       0.26      0.037508      0.993649  0.032174  0.993470\n",
      "24       0.25      0.037821      0.993494  0.032627  0.993302\n",
      "25       0.24      0.037821      0.993494  0.032627  0.993302\n",
      "26       0.23      0.037821      0.993494  0.032627  0.993302\n",
      "27       0.22      0.245226      0.965425  0.241758  0.965885\n",
      "28       0.21      0.245511      0.965319  0.242098  0.965770\n",
      "29       0.20      0.262017      0.963227  0.259998  0.963496\n",
      "30       0.19      0.285865      0.958317  0.285261  0.958625\n",
      "31       0.18      0.285865      0.958317  0.285261  0.958625\n",
      "32       0.17      0.285865      0.958317  0.285261  0.958625\n",
      "33       0.16      0.322946      0.953044  0.325365  0.953282\n",
      "34       0.15      0.322946      0.953044  0.325365  0.953282\n",
      "35       0.14      0.323003      0.953019  0.325479  0.953256\n",
      "36       0.13      0.363414      0.948700  0.362411  0.948753\n",
      "37       0.12      0.363414      0.948700  0.362411  0.948753\n",
      "38       0.11      0.444008      0.938254  0.445791  0.938238\n",
      "39       0.10      0.444037      0.938226  0.445791  0.938220\n",
      "40       0.09      0.444236      0.937809  0.446018  0.937787\n",
      "41       0.08      0.448021      0.935498  0.449643  0.935378\n",
      "42       0.07      0.448021      0.935498  0.449643  0.935378\n",
      "43       0.06      0.448021      0.935498  0.449643  0.935378\n",
      "44       0.05      0.484504      0.930235  0.484763  0.929991\n",
      "45       0.04      0.537864      0.918492  0.540841  0.918316\n",
      "46       0.03      0.735963      0.904510  0.742834  0.904532\n",
      "47       0.02      0.757136      0.411255  0.764586  0.412074\n",
      "48       0.01      0.807792      0.139692  0.812394  0.139735\n",
      "49       0.00      1.000000      0.000000  1.000000  0.000000\n",
      "    threshold  Training TPR  Training TNR  Test TPR  Test TNR\n",
      "38       0.11      0.444008      0.938254  0.445791  0.938238\n",
      "39       0.10      0.444037      0.938226  0.445791  0.938220\n",
      "40       0.09      0.444236      0.937809  0.446018  0.937787\n",
      "41       0.08      0.448021      0.935498  0.449643  0.935378\n",
      "42       0.07      0.448021      0.935498  0.449643  0.935378\n",
      "43       0.06      0.448021      0.935498  0.449643  0.935378\n",
      "44       0.05      0.484504      0.930235  0.484763  0.929991\n",
      "45       0.04      0.537864      0.918492  0.540841  0.918316\n",
      "46       0.03      0.735963      0.904510  0.742834  0.904532\n",
      "47       0.02      0.757136      0.411255  0.764586  0.412074\n",
      "48       0.01      0.807792      0.139692  0.812394  0.139735\n",
      "49       0.00      1.000000      0.000000  1.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "# We choose the second model for its lower AIC. However both models cannot predict any positive cases ('Closed with monetary relief') because there are just over 2.5% of these in the dataset. \n",
    "#We will test different thresholds to see which has the best balance between True Positive Rate and True Negative Rate. \n",
    "\n",
    "ROC_df = pd.DataFrame({\"threshold\": [], \n",
    "                       \"Training TPR\": [], \n",
    "                       \"Training TNR\": [], \n",
    "                       \"Test TPR\": [], \n",
    "                       \"Test TNR\": []})\n",
    "\n",
    "for threshold in np.arange(0, 0.5, 0.01): \n",
    "    predictions_train = (model2.predict(x_train[['ProductCodes','IssueCodes']].astype(float)) > threshold).astype(int)\n",
    "    predictions_test = (model2.predict(x_test[['ProductCodes','IssueCodes']].astype(float)) > threshold).astype(int)\n",
    "    tn1, fp1, fn1, tp1 = confusion_matrix(y_train, predictions_train).ravel()\n",
    "    tn2, fp2, fn2, tp2 = confusion_matrix(y_test, predictions_test).ravel()\n",
    "    ROC_df.loc[-1] = [threshold, tp1 / (tp1 + fn1), tn1 / (tn1 + fp1), tp2 / (tp2 + fn2), tn2 / (tn2 + fp2)]\n",
    "    ROC_df.index = ROC_df.index + 1\n",
    "    ROC_df = ROC_df.sort_index()\n",
    "\n",
    "print(ROC_df.head(50))\n",
    "print(ROC_df.tail(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose 0.10 as our threshold, because it has the best balance between True Positive Rate and True Negative Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With a threshold of 0.1 the Product & Issue with the highest predicted percentage 'Closed with monetary relief' is Product_Issue:'Credit card or prepaid card_Fees or interest' which has a probability of: 0.364\n",
      "\n",
      "With a threshold of 0.1 count of Product 'Closed with monetary relief' in test dataset:\n",
      "Product\n",
      "Credit card or prepaid card                                                     3752\n",
      "Checking or savings account                                                     2930\n",
      "Money transfer, virtual currency, or money service                               695\n",
      "Mortgage                                                                         574\n",
      "Credit reporting, credit repair services, or other personal consumer reports     332\n",
      "Debt collection                                                                  215\n",
      "Payday loan, title loan, or personal loan                                        139\n",
      "Vehicle loan or lease                                                            137\n",
      "Student loan                                                                      53\n",
      "Name: count, dtype: int64\n",
      "\n",
      "With a threshold of 0.1 probability of Product 'Closed with monetary relief' in test dataset:\n",
      "Product\n",
      "Credit card or prepaid card                                                     0.176374\n",
      "Checking or savings account                                                     0.161193\n",
      "Money transfer, virtual currency, or money service                              0.097257\n",
      "Payday loan, title loan, or personal loan                                       0.048247\n",
      "Mortgage                                                                        0.038765\n",
      "Vehicle loan or lease                                                           0.028788\n",
      "Student loan                                                                    0.016526\n",
      "Debt collection                                                                 0.005836\n",
      "Credit reporting, credit repair services, or other personal consumer reports    0.001388\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Using the test dataset predict the product using model 2 with a 0.1 threshold.\n",
    "\n",
    "threshold = 0.10\n",
    "predictions = (model2.predict(x_test[['ProductCodes','IssueCodes']].astype(float)) > threshold).astype(int)\n",
    "\n",
    "results_all_df = pd.DataFrame({'Actual': y_test, 'Predicted_Probability': predictions, 'Product': x_test['ProductCodes'], 'Issue': x_test['IssueCodes']})\n",
    "\n",
    "# Define a dictionary mapping product codes to product names\n",
    "product_code_to_name = {code: name for code, name in zip(x_test['ProductCodes'], x_test['Product'])}\n",
    "\n",
    "# Define a dictionary mapping product codes to product names\n",
    "state_code_to_name = {code: name for code, name in zip(x_test['IssueCodes'], x_test['Issue'])}\n",
    "\n",
    "\n",
    "# Map product codes to product names in the DataFrame\n",
    "results_all_df['Product'] = results_all_df['Product'].map(product_code_to_name)\n",
    "\n",
    "# Map product codes to product names in the DataFrame\n",
    "results_all_df['Issue'] = results_all_df['Issue'].map(state_code_to_name)\n",
    "\n",
    "results_all_df.head()\n",
    "\n",
    "\n",
    "results_all_df['Product_Issue'] = results_all_df['Product'] + '_' + results_all_df['Issue']\n",
    "\n",
    "#Count the occurrences of each value in the 'Product' table\n",
    "product_issue_counts = results_all_df['Product_Issue'].value_counts()\n",
    "\n",
    "positive_outcomes_df = results_all_df[results_all_df['Actual'] == 1]\n",
    "\n",
    "# Count the occurrences of a positive outcome ('Closed with monetary relief' = 1) for each value in the 'Product' table\n",
    "positive_outcomes_counts = positive_outcomes_df['Product_Issue'].value_counts()\n",
    "positive_outcomes_counts = positive_outcomes_counts.sort_values(ascending=False)\n",
    "\n",
    "#print(positive_outcomes_counts.head(10))\n",
    "#print(\"\\nThe Product & Issue combination which has the highest predicted number of 'Closed with monetary relief' is: '\" + positive_outcomes_counts.index[0] + \"' at \" + str(positive_outcomes_counts.iloc[0]))\n",
    "\n",
    "# Divide positive outcomes counts by product counts to get probability of each product value\n",
    "output_per_value = positive_outcomes_counts / product_issue_counts\n",
    "\n",
    "# Display the output\n",
    "#print(\"\\nWith a threshold of \" + str(threshold) + \" the probability each Product category is 'Closed with monetary relief' in descending order:\\n\")\n",
    "output_per_value = output_per_value.sort_values(ascending=False)\n",
    "#print(output_per_value)\n",
    "print(\"\\nWith a threshold of \" + str(threshold) + \" the Product & Issue with the highest predicted percentage 'Closed with monetary relief' is Product_Issue:'\" + output_per_value.index[0] + \"' which has a probability of: \" + str(round(output_per_value.iloc[0],3)))\n",
    "\n",
    "\n",
    "#Getting counts of individual Product and Issue from the predicted dataset\n",
    "results_all_df['Product'] = results_all_df['Product'] \n",
    "results_all_df['Issue'] = results_all_df['Issue']\n",
    "positive_outcomes_product_counts = positive_outcomes_df['Product'].value_counts().fillna(0)\n",
    "positive_outcomes_product_counts =positive_outcomes_product_counts.sort_values(ascending=False)\n",
    "product_counts = results_all_df['Product'].value_counts()\n",
    "product_test_probability = positive_outcomes_product_counts/product_counts\n",
    "product_test_probability = product_test_probability.sort_values(ascending=False).fillna(0)\n",
    "\n",
    "issue_counts = results_all_df['Issue'].value_counts()\n",
    "positive_outcomes_issue_counts = positive_outcomes_df['Issue'].value_counts().fillna(0)\n",
    "positive_outcomes_issue_counts = positive_outcomes_issue_counts.sort_values(ascending=False)\n",
    "issue_test_probability = positive_outcomes_issue_counts/issue_counts\n",
    "issue_test_probability = issue_test_probability.sort_values(ascending=False).fillna(0)\n",
    "\n",
    "#print(\"\\nCount of Product in test dataset:\")\n",
    "#print(results_all_df['Product'].head())\n",
    "#print(results_all_df['Product'].value_counts())\n",
    "\n",
    "print(\"\\nWith a threshold of \" + str(threshold) + \" count of Product 'Closed with monetary relief' in test dataset:\")\n",
    "print(positive_outcomes_product_counts)\n",
    "print(\"\\nWith a threshold of \" + str(threshold) + \" probability of Product 'Closed with monetary relief' in test dataset:\")\n",
    "print(product_test_probability)\n",
    "\n",
    "product_test_probability.to_csv('Product_probability.csv')\n",
    "\n",
    "#print(\"\\nCount of Issue in test dataset:\")\n",
    "#print(results_all_df['Product'].head())\n",
    "#print(results_all_df['Issue'].value_counts())\n",
    "\n",
    "#print(\"\\nCount of Issue 'Closed with monetary relief' in test dataset:\")\n",
    "#print(positive_outcomes_issue_counts)\n",
    "#print(\"\\nProbability of Issue 'Closed with monetary relief' in test dataset:\")\n",
    "#print(issue_test_probability)\n",
    "\n",
    "#print(\"\\n Top 2 Results of Product:\" + results_all_df['Product'].index[0])  #.head(2))\n",
    "\n",
    "\n",
    "#print(positive_outcomes_product_counts)\n",
    "#print(\"The total predicted Product number in the test set 'Closed with monetary relief' is: \" + positive_outcomes_product_counts) #+ \" which has an overall probability of \"  + (positive_outcomes_product_counts/product_counts))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OH', 'TN', 'FL', 'PA', 'CA', 'TX', 'VA', 'MO', 'GA', 'NY', 'CO',\n",
       "       'WA', 'MN', 'AL', 'IL', 'NC', 'OK', 'MD', 'MI', 'LA', 'SC', nan,\n",
       "       'OR', 'NH', 'IN', 'NJ', 'DC', 'UT', 'KY', 'NV', 'MA', 'AA', 'RI',\n",
       "       'KS', 'DE', 'WI', 'MS', 'NM', 'PR', 'NE', 'CT', 'AR', 'AZ', 'IA',\n",
       "       'ME', 'HI', 'WV', 'ID', 'ND', 'MT',\n",
       "       'UNITED STATES MINOR OUTLYING ISLANDS', 'AE', 'WY', 'GU', 'SD',\n",
       "       'AK', 'AP', 'VI', 'VT', 'MP', 'AS', 'MH'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique values of States Column\n",
    "\n",
    "states_list = df_Group6['State']\n",
    "states_list.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of State initials and Full Name\n",
    "\n",
    "state_names = {\n",
    "    'OH': 'Ohio',\n",
    "    'TN': 'Tennessee',\n",
    "    'FL': 'Florida',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'CA': 'California',\n",
    "    'TX': 'Texas',\n",
    "    'VA': 'Virginia',\n",
    "    'MO': 'Missouri',\n",
    "    'GA': 'Georgia',\n",
    "    'NY': 'New York',\n",
    "    'CO': 'Colorado',\n",
    "    'WA': 'Washington',\n",
    "    'MN': 'Minnesota',\n",
    "    'AL': 'Alabama',\n",
    "    'IL': 'Illinois',\n",
    "    'NC': 'North Carolina',\n",
    "    'OK': 'Oklahoma',\n",
    "    'MD': 'Maryland',\n",
    "    'MI': 'Michigan',\n",
    "    'LA': 'Louisiana',\n",
    "    'SC': 'South Carolina',\n",
    "    'nan': 'Unknown',\n",
    "    'OR': 'Oregon',\n",
    "    'NH': 'New Hampshire',\n",
    "    'IN': 'Indiana',\n",
    "    'NJ': 'New Jersey',\n",
    "    'DC': 'Washington DC',\n",
    "    'UT': 'Utah',\n",
    "    'KY': 'Kentucky',\n",
    "    'NV': 'Nevada',\n",
    "    'MA': 'Massachusetts',\n",
    "    'AA': 'Armed Forces America',\n",
    "    'RI': 'Rhode Island',\n",
    "    'KS': 'Kansas',\n",
    "    'DE': 'Delaware',\n",
    "    'WI': 'Wisconsin',\n",
    "    'MS': 'Mississippi',\n",
    "    'NM': 'New Mexico',\n",
    "    'PR': 'Puerto Rico',\n",
    "    'NE': 'Nebraska',\n",
    "    'CT': 'Connecticut',\n",
    "    'AR': 'Arkansas',\n",
    "    'AZ': 'Arizona',\n",
    "    'IA': 'Iowa',\n",
    "    'ME': 'Maine',\n",
    "    'HI': 'Hawaii',\n",
    "    'WV': 'West Virginia',\n",
    "    'ID': 'Idaho',\n",
    "    'ND': 'North Dakota',\n",
    "    'MT': 'Montana',\n",
    "    'UNITED STATES MINOR OUTLYING ISLANDS':'UNITED STATES MINOR OUTLYING ISLANDS',\n",
    "    'AE': 'Armed Forces',\n",
    "    'WY': 'Wyoming',\n",
    "    'GU': 'Guam',\n",
    "    'SD': 'South Dakota',\n",
    "    'AK': 'Alaska',\n",
    "    'AP': 'Armed Forces Pacific',\n",
    "    'VI': 'Virgin Islands',\n",
    "    'VT': 'Vermont',\n",
    "    'MP': 'Northern Mariana Islands',\n",
    "    'AS': 'American Samoa',\n",
    "    'MH': 'Marshall Islands'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace state initials with full names\n",
    "df_Group6['State']=states_list.map(state_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting updated dataset to use in Tableau\n",
    "\n",
    "df_Group6.to_csv('Group6-TableauExport.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
